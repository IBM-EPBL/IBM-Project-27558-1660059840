{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtZq1JyHZ-Wg",
        "outputId": "e2b6a84a-d5ae-4d3c-f22b-b5a27b198694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import ImageDatageneratorLibrary\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np #numerical analysis \n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "#Dense layer is regularly deeply connected neural network layer\n",
        "#MaxPooling2D to downsample the image\n",
        "from keras.layers import Conv2D, Dropout, Dense, Flatten, MaxPooling2D, SeparableConv2D, Activation, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array "
      ],
      "metadata": {
        "id": "Jw6IZ7WJdVvo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configure ImageDatGenerator Class \n",
        "#Define the parameters/arguments for ImageDataGenerator class\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 shear_range=0.2,\n",
        "                                 rotation_range=180,\n",
        "                                 zoom_range=0.2,\n",
        "                                 width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                 horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "4dfQ28rFdXRD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying ImageDataGenerator functionality to train data \n",
        "\n",
        "x_train =train_datagen.flow_from_directory(r\"/content/drive/MyDrive/dataset/train_set\",\n",
        "                                           target_size = (64,64),\n",
        "                                           batch_size=5,\n",
        "                                           color_mode='rgb',\n",
        "                                           class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDN3W6CNdqLd",
        "outputId": "09aeacc2-d460-470d-95ed-3efc0a466edf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 742 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying ImageDataGenerator functionality to test data \n",
        "\n",
        "x_test =test_datagen.flow_from_directory(r\"/content/drive/MyDrive/dataset/test_set\",\n",
        "                                         target_size = (64,64), \n",
        "                                         batch_size=5,color_mode='rgb',\n",
        "                                         class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfU12CHFdqIX",
        "outputId": "995a4f80-457c-4eef-9117-03acfd8c8332"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 198 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing the model\n",
        "model=Sequential()\n",
        "\n",
        "#add convolutional, maxpooling and flatten layers\n",
        "model.add(Conv2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "#add Dense Layer \n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=4,activation='softmax'))"
      ],
      "metadata": {
        "id": "-0eaoz5Yocl2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptH3fhOyjFLM",
        "outputId": "57012916-29f9-4bd2-b27e-79c60f4c755d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,604\n",
            "Trainable params: 813,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configure the learning process\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "tWOF7lybjfBm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7joLxTdSse2C",
        "outputId": "f7205b3c-4906-43b7-acae-4df4d53d7699"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "history = model.fit(x_train,epochs=20,\n",
        "                    steps_per_epoch=len(x_train),\n",
        "                    validation_data=x_test,validation_steps=len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5mzr74_Z34U",
        "outputId": "d86f39e7-ee42-43a3-a611-fe5d7e460dad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "149/149 [==============================] - 433s 3s/step - loss: 1.2881 - accuracy: 0.3760 - val_loss: 1.3300 - val_accuracy: 0.3687\n",
            "Epoch 2/20\n",
            "149/149 [==============================] - 42s 282ms/step - loss: 1.1973 - accuracy: 0.4245 - val_loss: 1.1797 - val_accuracy: 0.4747\n",
            "Epoch 3/20\n",
            "149/149 [==============================] - 39s 263ms/step - loss: 1.1052 - accuracy: 0.5229 - val_loss: 1.2172 - val_accuracy: 0.3990\n",
            "Epoch 4/20\n",
            "149/149 [==============================] - 43s 286ms/step - loss: 1.0283 - accuracy: 0.5701 - val_loss: 0.8173 - val_accuracy: 0.7576\n",
            "Epoch 5/20\n",
            "149/149 [==============================] - 42s 283ms/step - loss: 0.8643 - accuracy: 0.6321 - val_loss: 0.8074 - val_accuracy: 0.6162\n",
            "Epoch 6/20\n",
            "149/149 [==============================] - 42s 281ms/step - loss: 0.8421 - accuracy: 0.6590 - val_loss: 0.9828 - val_accuracy: 0.6263\n",
            "Epoch 7/20\n",
            "149/149 [==============================] - 41s 275ms/step - loss: 0.7803 - accuracy: 0.6968 - val_loss: 0.6238 - val_accuracy: 0.7576\n",
            "Epoch 8/20\n",
            "149/149 [==============================] - 41s 274ms/step - loss: 0.7736 - accuracy: 0.6887 - val_loss: 1.0831 - val_accuracy: 0.5505\n",
            "Epoch 9/20\n",
            "149/149 [==============================] - 41s 274ms/step - loss: 0.7418 - accuracy: 0.6995 - val_loss: 0.9377 - val_accuracy: 0.6414\n",
            "Epoch 10/20\n",
            "149/149 [==============================] - 39s 260ms/step - loss: 0.7359 - accuracy: 0.7022 - val_loss: 0.5673 - val_accuracy: 0.8030\n",
            "Epoch 11/20\n",
            "149/149 [==============================] - 41s 275ms/step - loss: 0.6837 - accuracy: 0.7170 - val_loss: 0.7470 - val_accuracy: 0.6970\n",
            "Epoch 12/20\n",
            "149/149 [==============================] - 43s 286ms/step - loss: 0.7117 - accuracy: 0.7089 - val_loss: 0.6784 - val_accuracy: 0.7374\n",
            "Epoch 13/20\n",
            "149/149 [==============================] - 41s 276ms/step - loss: 0.6764 - accuracy: 0.7278 - val_loss: 0.6760 - val_accuracy: 0.7071\n",
            "Epoch 14/20\n",
            "149/149 [==============================] - 40s 264ms/step - loss: 0.6868 - accuracy: 0.7385 - val_loss: 0.7151 - val_accuracy: 0.7121\n",
            "Epoch 15/20\n",
            "149/149 [==============================] - 41s 275ms/step - loss: 0.6730 - accuracy: 0.7358 - val_loss: 0.6104 - val_accuracy: 0.7828\n",
            "Epoch 16/20\n",
            "149/149 [==============================] - 39s 263ms/step - loss: 0.6366 - accuracy: 0.7412 - val_loss: 0.6514 - val_accuracy: 0.7879\n",
            "Epoch 17/20\n",
            "149/149 [==============================] - 41s 278ms/step - loss: 0.6076 - accuracy: 0.7588 - val_loss: 0.8053 - val_accuracy: 0.7374\n",
            "Epoch 18/20\n",
            "149/149 [==============================] - 39s 264ms/step - loss: 0.6519 - accuracy: 0.7520 - val_loss: 0.5709 - val_accuracy: 0.7879\n",
            "Epoch 19/20\n",
            "149/149 [==============================] - 41s 275ms/step - loss: 0.6330 - accuracy: 0.7520 - val_loss: 0.6790 - val_accuracy: 0.7374\n",
            "Epoch 20/20\n",
            "149/149 [==============================] - 41s 277ms/step - loss: 0.5975 - accuracy: 0.7642 - val_loss: 0.6436 - val_accuracy: 0.7323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save('disaster.h5')\n",
        "model_json = model.to_json()\n",
        "with open(\"model-bw.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "metadata": {
        "id": "r3CxDVnEkjCf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#load the saved model\n",
        "model = load_model(\"forest1.h5\")"
      ],
      "metadata": {
        "id": "ZgqI91a5xryB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load image\n",
        "img=load_img(r\"/content/drive/MyDrive/dataset/test_set/Earthquake/1321.jpg\",target_size=(64,64))\n",
        "x=img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
        "\n",
        "#predict class \n",
        "y=np.argmax(model.predict(x),axis=1)\n",
        "print(index[int(y)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_TBckDhkzYQ",
        "outputId": "fa76c9fe-4ec7-43c0-9bed-98580a845519"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 211ms/step\n",
            "Earthquake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYmPDtPFmJVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}